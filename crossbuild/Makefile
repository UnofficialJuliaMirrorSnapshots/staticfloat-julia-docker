include ../common.mk

# Make our own HFS off of the files in this directory
HFS:=$(subst .Dockerfile,,$(wildcard *.Dockerfile))
BUILD_HFS=$(call arch_filt,$(BUILD_ARCHS),$(HFS))

# Build "dockerfiles" target that assembles all Dockerfiles
$(foreach f,$(HFS),$(eval $(call add_dep,dockerfiles,build/$(f)/Dockerfile)))

# Build "buildall" target that attempts to build every Dockerfile in the room,
# but only from the ones that our build architecture can manage.
$(foreach f,$(BUILD_HFS),$(eval $(call add_dep,buildall,build-$(f))))

# Build "pushall" target that pushes up the result of "buildall"
#$(foreach f,$(BUILD_HFS),$(eval $(call add_dep,pushall,push-$(f))))

# This is where we put our derived Dockerfiles
lib:
	ln -sf ../workerbase/lib lib
patches:
	ln -sf ../workerbase/patches patches

# Temporary folder for generated output
SHELL=/bin/bash
TMPDIR=/tmp

define build_dockerfile
# Running just `make build-crossshard-x86_64-linux-gnu-x64` will build that image
build-$(1): build/$(1)/Dockerfile
	docker build -t $(call crossbuild_tag_name,$(1)) "build/$(1)"

buildsquash-$(1): build/$(1)/Dockerfile
	$(DOCKER_BUILD) --pull -t $(call crossbuild_tag_name,$(1)) "build/$(1)"

shell-$(1):
	docker run -ti $(call crossbuild_tag_name,$(1))

# Running `make push-ubuntu16_04-x86` will upload that image to
#push-$(1): buildsquash-$(1)
#	docker push $(call crossbuild_tag_name,$(1))

# This is how we build the actual Dockerfile
build/$(1)/Dockerfile: Makefile lib patches $(shell ../dockerdeps $(1).Dockerfile)
	@if [ ! -f "$(1).Dockerfile" ]; then \
		echo "Target \"$(1)\" is invalid, recheck your spelling good sir."; \
		exit 1; \
	fi
	@mkdir -p "build/$(1)"
	@rm -f "build/$(1)/Dockerfile.tmp"

	@# Build the altered Dockerfile
	@echo "$(1).Dockerfile"
	@../dockerchain "./$(1).Dockerfile" > "build/$(1)/Dockerfile.tmp"
	@echo "## This file was autogenerated" > "build/$(1)/Dockerfile"
	@echo "# Do not edit directly; edit the .Dockerfile files" >> "build/$(1)/Dockerfile"
	@echo "#" >> "build/$(1)/Dockerfile"
	@echo "# To build this docker image via \`make\`, run \`make build-$(1)\` in the \`crossbuild\` directory" >> "build/$(1)/Dockerfile"
	@echo "# To build this docker image manually, run \`docker build --pull -t $(call crossbuild_tag_name,$(1)) .\`" >> "build/$(1)/Dockerfile"
	@echo >> "build/$(1)/Dockerfile"
	@cat "build/$(1)/Dockerfile.tmp" >> "build/$(1)/Dockerfile"
	@rm -f "build/$(1)/Dockerfile.tmp"
	@cp -L lib/*.sh "build/$(1)/"
	@mkdir -p "build/$(1)/crossbuild"
	@cp -L lib/crossbuild/*.sh "build/$(1)/crossbuild/"
	cp -LR cmake_toolchains "build/$(1)/"
	cp -LR patches "build/$(1)/"
endef

# Special dependency rules to ensure that the shards are built in the right orders
TARGETS = $(patsubst crossshard-%-x64.Dockerfile,%,$(wildcard crossshard-*-x64.Dockerfile))
BUILD_TARGETS = $(patsubst %,build-crossshard-%-x64,$(TARGETS))
$(foreach f,$(BUILD_TARGETS),$(eval $(f): crossbase-x64.Dockerfile))

# Generate build- rules for each dockerfile in the directory
$(foreach f,$(HFS),$(eval $(call build_dockerfile,$(f))))

# This is how we make .sha256 files
%.sha256: %
	@shasum -a 256 $< | cut -d' ' -f1 > $@

# We have special options to squash things with
SQUASHFS_OPTS=-force-uid 0 -force-gid 0 -comp xz -b 1048576 -Xdict-size 100% -noappend

# This is where the shards get uploaded
S3_PREFIX=s3://julialangmirror/binarybuilder

define shard_build_recipe
# Rule to extract a shard out into a .tar file (what docker natively exports)
$(TMPDIR)/rootfs-$(1).tar:
	@echo "Exporting $(1) shard to $$@"
	@if [ "$(1)" == "base" ]; then \
		IMG_NAME=staticfloat/julia_crossbase:x64; \
	else \
		IMG_NAME=staticfloat/julia_crossshard-$(1):x64; \
	fi; \
	CONTAINER_ID=$$$$(docker run -ti --rm -d $$$$IMG_NAME bash); \
	echo "Running in container $$$$CONTAINER_ID, exporting..."; \
	docker export $$$$CONTAINER_ID -o $$@; \
	echo "Stopping container $$$$CONTAINER_ID..."; \
	docker stop $$$$CONTAINER_ID >/dev/null

# Add docker build dependency
#ifeq ($(1),base)
#$(TMPDIR)/rootfs-$(1).tar: build-crossbase-x64
#else
#$(TMPDIR)/rootfs-$(1).tar: build-crossshard-$(1)-x64
#endif

# Rule to extract (and cleanup) a shard into a plain directory
$(TMPDIR)/rootfs-$(1): $(TMPDIR)/rootfs-$(1).tar
	@echo "Unpacking $$<..."
	@rm -rf $$@; mkdir -p $$@
	@tar -xf $$< -C $$@ --exclude='dev/null' --exclude='usr/share/terminfo'
	@if [ -d $$@/opt/$(1)/MacOSX*.sdk ]; then \
		echo "Removing OSX SDK..."; \
		rm -rf $$@/opt/$(1)/MacOSX*.sdk; \
	fi
	@if [ "$(1)" == "base" ]; then \
		echo "Cleaning up base image..."; \
		touch $$@/dev/null; \
		touch $$@/dev/urandom; \
		touch $$@/dev/ptmx; \
		echo "nameserver 8.8.8.8"  > $$@/etc/resolv.conf; \
		echo "nameserver 8.8.4.4" >> $$@/etc/resolv.conf; \
		echo "nameserver 4.4.4.4" >> $$@/etc/resolv.conf; \
	fi

# Rule to extract shard into a .tar.gz
$(TMPDIR)/rootfs-$(1).tar.gz: $(TMPDIR)/rootfs-$(1)
	@rm -f $$@
	@if [ "$(1)" == "base" ]; then SRC="$$<"; else SRC="$$</opt/$(1)"; fi; \
	echo "  Packaging $$@ shard from $$$$SRC..."; \
	GZIP=-9 tar zcf $$@ -C $$$$SRC .

# Rule to extract shard into a .squashfs
$(TMPDIR)/rootfs-$(1).squashfs: $(TMPDIR)/rootfs-$(1)
	@rm -f $$@
	@if [ "$(1)" == "base" ]; then SRC="$$<"; else SRC="$$</opt/$(1)"; fi; \
	echo "  Packaging $$@ shard from $$$$SRC..."; \
	mksquashfs $$$$SRC $$@ $(SQUASHFS_OPTS)

push-$(1): $(TMPDIR)/rootfs-$(1).tar.gz.sha256 $(TMPDIR)/rootfs-$(1).squashfs.sha256
	@ DATE_STR=$$$$(date +%Y-%m-%d); \
	for s in tar.gz squashfs; do \
		aws s3 cp --acl public-read $(TMPDIR)/rootfs-$(1).$$$${s} $(S3_PREFIX)-rootfs-$(1)-$$$${DATE_STR}.$$$${s}; \
		aws s3 cp --acl public-read $(TMPDIR)/rootfs-$(1).$$$${s}.sha256 $(S3_PREFIX)-rootfs-$(1)-$$$${DATE_STR}.$$$${s}.sha256; \
	done

clean-$(1):
	@rm -rf $(TMPDIR)/rootfs-$(1)
	@rm -f $(TMPDIR)/rootfs-$(1).tar
	@rm -f $(TMPDIR)/rootfs-$(1).tar.gz
	@rm -f $(TMPDIR)/rootfs-$(1).tar.gz.sha256
	@rm -f $(TMPDIR)/rootfs-$(1).squashfs
	@rm -f $(TMPDIR)/rootfs-$(1).squashfs.sha256
endef

# Generate a packaging routine for every triplet that we've got
$(foreach f,$(TARGETS),$(eval $(call shard_build_recipe,$(f))))
# Also for the base shard
$(eval $(call shard_build_recipe,base))

# Package 'em all up (we explicitly include push-base here, and then add
# push-$(target) below for all targets)
push-rootfs: push-base
	$(MAKE) print-hashes
$(foreach f,$(TARGETS),$(eval push-rootfs: push-$(f)))

# clean-rootfs deletes all intermediate products
clean-rootfs: clean-base
$(foreach f,$(TARGETS),$(eval clean-rootfs: clean-$(f)))


print-hashes:
	@# Print out the squashfs hashes first
	@echo "    rootfs_version = \"$$(date +%Y-%m-%d)\""
	@echo "    squashfs_hashes = Dict("
	@for f in $(TMPDIR)/rootfs-*.squashfs; do \
		f_prefix=$$(basename $${f%.*}); \
		triplet=$${f_prefix:7}; \
		echo "        \"$${triplet}\" => \"$$(cat $${f}.sha256)\","; \
	done
	@echo "    )"
	@# Then print out the tarball hashes:
	@echo "    tarball_hashes = Dict("
	@for f in $(TMPDIR)/rootfs-*.tar.gz; do \
		f_prefix=$$(basename $${f%.*.*}); \
		triplet=$${f_prefix:7}; \
		echo "        \"$${triplet}\" => \"$$(cat $${f}.sha256)\","; \
	done
	@echo "    )"

clean:
	rm -rf build lib patches
